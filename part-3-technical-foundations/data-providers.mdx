---
title: "Data Providers"
description: "Understanding external data vendors who supply information about companies, funding, people, and markets - and how to use them effectively."
---

## Overview

You can't build VC infrastructure using only internal data. You need external data about companies, funding, people, markets, and competitors. This data comes from third-party vendors who specialize in aggregating, verifying, and delivering information about the startup ecosystem.

Data providers are foundational to your tech stack. They feed your CRM with company information. They power your sourcing tools with signals about new companies. They enrich your data warehouse with funding data, employee counts, and market context. They help you research markets and track competitors.

But data providers are expensive, have different strengths and weaknesses, and deliver data in different ways. Choosing the right providers and using them effectively is critical to building good infrastructure without wasting budget.

This chapter covers what types of data you need, which vendors provide it, how they deliver data (APIs vs files), what they cost, and how to work with them effectively. We'll leave placeholders for specific vendor recommendations that you can fill in based on your needs.

## Types of Data You Need

VC funds need several categories of external data, each served by different providers.

**Company and funding data**: Basic information about companies (name, location, founding date, description, website) and their funding history (rounds, amounts, dates, investors, valuations). This is the foundation of your deal flow tracking, market analysis, and portfolio monitoring.

**People data**: Information about founders, executives, and employees. Who founded the company, who's on the leadership team, how many employees they have, where they're hiring. Essential for evaluating teams, tracking talent movement, and understanding company growth.

**Signal and sourcing data**: Early indicators that companies are growing, raising funding, or becoming interesting. Job postings, web traffic, social media activity, product launches, hiring velocity. Used by sourcing tools to identify companies before they're widely known.

**Market and competitive data**: Information about sectors, industries, technology trends, and competitive landscapes. What companies operate in a space, how markets are evolving, what technologies are emerging.

**Financial and operational data**: For public companies or later-stage private companies: revenue, growth rates, financials, metrics. Less available for early-stage companies but valuable for growth equity or follow-on analysis.

Different vendors specialize in different categories. Some provide comprehensive coverage across categories (but are expensive). Others focus deeply on one type (and are more affordable). You'll likely use multiple vendors to cover your needs.

## Popular Data Providers by Category

This is a starting point, not a comprehensive list. Many providers fall into multiple categories. If you're a data provider and want to be featured, please file a GitHub issue.

**Company and Investment Data:**
- [PitchBook](https://pitchbook.com/)
- [Crunchbase](https://www.crunchbase.com/)
- [Dealroom](https://dealroom.co/)

**People Data:**
- [People Data Labs](https://www.peopledatalabs.com/)
- [Coresignal](https://coresignal.com/)
- [Mixrank](https://mixrank.com/)

**Signal and Sourcing Data:**
- [Harmonic](https://harmonic.ai/)
- [Specter](https://www.usespecter.com/)
- [Evertrace](https://www.evertrace.io/)
- [Gravity](https://www.gravity.inc/)

**Market Data:**
- [S&P Capital IQ](https://www.spglobal.com/marketintelligence/en/solutions/sp-capital-iq-platform) (public markets)

**Research:**
- [Lens](https://www.lens.org/)
- [arXiv](https://arxiv.org/)

**General guidance on choosing vendors:**
- Start with what your fund actually needs (don't subscribe to everything)
- Test accuracy with your portfolio companies ([Data Quality](/part-3-technical-foundations/data-quality))
- Consider whether you need comprehensive coverage or can start smaller
- Factor in API access, documentation quality, and support

## Data Delivery Methods

Data providers deliver data in two main ways: APIs and files. Each has different implications for how you build integrations.

**API-based delivery**

Most modern vendors provide REST APIs. You authenticate with an API token, make HTTP requests, and receive JSON responses. This is real-time or near-real-time: when you need data about a company, you query the API and get current information.

**Benefits:**
- Real-time or near-real-time data
- Query exactly what you need (don't download everything)
- Easy to integrate into applications (CRM enrichment, sourcing tools)
- Can build interactive features (search, live updates)

**Considerations:**
- Rate limits (covered in [Integrations and APIs](/part-3-technical-foundations/integrations-and-apis))
- Per-request or per-entity costs (each API call might cost money)
- Need to handle failures, retries, validation ([Integrations and APIs](/part-3-technical-foundations/integrations-and-apis))
- API schemas change over time

**File-based delivery**

Some vendors provide data as file exports: CSV, Parquet, or JSON files that you download or they upload to your S3 bucket. This is common for bulk data (entire company database, historical funding data, quarterly dumps).

**Benefits:**
- Can be cheaper than API calls for bulk data
- Get everything at once (good for analytics, data warehouse loading)
- Predictable costs (usually flat fee for the export)
- No rate limits once you have the file

**Considerations:**
- Data is a snapshot (not real-time, might be hours or days old)
- Need to process and load files (use Dagster, Airflow, or BigQuery Data Transfer)
- File format matters significantly

**Prefer Parquet over CSV/TSV**

If vendors offer multiple file formats, always choose Parquet. It's columnar (faster for analytics), includes schema information (you know data types without guessing), compresses well (smaller files), and loads much faster into data warehouses.

CSV/TSV files require parsing, have encoding issues, no schema, and are slower to work with. Ask vendors to provide Parquet if they don't already. Most modern vendors support it, and it will save you significant time and headaches.

**Hybrid approaches**

Some vendors offer both APIs (for real-time enrichment) and bulk exports (for loading your data warehouse). This is ideal: use the API for interactive features, use bulk exports to populate your data warehouse efficiently.

## Authentication and Access

**API authentication**

Most vendors use API tokens (also called API keys). You get a token from the vendor (usually through their dashboard), include it in your HTTP requests (usually as a Bearer token in the Authorization header), and the vendor identifies your account and tracks usage.

Store API tokens securely:
- Use environment variables, not hardcoded in code
- Use a secrets manager (AWS Secrets Manager, 1Password) for production
- Never commit tokens to git
- Rotate tokens periodically (every 6-12 months)
- Have separate tokens for development, staging, production

**File delivery authentication**

For file-based vendors, they usually:
- Upload files to their own S3 bucket that you can access (they provide AWS credentials)
- Upload files directly to your S3 bucket (you provide them with write-only credentials)
- Provide download links through their portal (you download manually or via script)

The third option (manual download) doesn't scale well. Prefer vendors who can integrate with your cloud storage.

**IP allowlisting**

Some vendors require you to allowlist IP addresses that will access their API. This is more common with financial data vendors or those handling sensitive information. Plan for this in your infrastructure (static IPs for your servers, or NAT gateways for cloud deployments).

## Data Quality Considerations

Not all data providers are equally accurate or comprehensive. Quality varies significantly between vendors and even within the same vendor for different data types.

**Accuracy vs speed tradeoffs**

As covered in [Data Quality](/part-3-technical-foundations/data-quality), some vendors prioritize accuracy (verify information before publishing, resulting in lag), others prioritize speed (publish quickly, may have more errors). PitchBook is accurate but slow. Signal providers are fast but incomplete.

Choose based on your use case. For LP reporting or board materials, use accurate vendors. For early sourcing signals, speed matters more than perfection.

**Coverage differences**

Vendors have different coverage by stage, geography, and sector:
- Some excel at early-stage companies (Harmonic, Specter)
- Some excel at later-stage (PitchBook for established companies)
- Some have strong US coverage but weak international
- Some focus on specific sectors (deep tech, bio, fintech)

**Test with your portfolio companies**

The best way to evaluate vendor accuracy is to check their data against companies you know well: your portfolio companies. Take 10-20 portfolio companies and see how accurately each vendor represents them:
- Is funding data correct (amounts, dates, investors)?
- Are employee counts reasonable?
- Are descriptions accurate?
- How quickly do they update after new events?

This gives you ground truth for choosing vendors and understanding their limitations. Document what each vendor is good for and what they're not.

**Data freshness**

Different vendors update at different cadences:
- Real-time (APIs that reflect changes within hours)
- Daily (updated nightly)
- Weekly or monthly (bulk refreshes)
- Quarterly (some datasets update only when they do major refreshes)

Know how fresh the data is and factor that into how you use it. Don't present 6-month-old employee counts as if they're current.

## Cost Considerations

Data providers are expensive. Budget for them appropriately and understand different pricing models.

**Pricing models**

**Per-request or per-entity**: You pay for each API call or each entity returned. People Data Labs might charge $0.01 per person record. This is predictable per query but can add up quickly with high usage.

**Usage tiers**: Pay based on total monthly usage (number of API calls, entities accessed, etc.). Might be $500/month for 10,000 requests, $2,000/month for 50,000 requests, etc. Good if usage is steady and predictable.

**Flat subscriptions**: Pay a fixed amount per year for unlimited (or high-limit) access. Common for established vendors. Might be $10,000-100,000+ per year depending on the vendor and what you're accessing.

**Per-seat pricing**: Pay per user who has access (common for platforms with dashboards, less common for APIs). Doesn't scale well for programmatic access.

**Cost management strategies**

- **Start with what you actually need**: Don't subscribe to every vendor. Figure out your critical use cases and buy data for those first.

- **Monitor spending**: Set up alerts when API usage or costs exceed thresholds. It's easy to accidentally rack up bills with per-request pricing.

- **Cache data**: Don't request the same company data repeatedly. Cache responses (in your database or redis) with appropriate TTLs. This saves money and respects rate limits.

- **Use bulk exports when possible**: If you need to load lots of data into your warehouse, bulk exports are usually cheaper than making thousands of API requests.

- **Negotiate**: Especially with newer vendors, negotiate based on your expected usage. They want customers and are often flexible on pricing.

**Budget planning**

Data costs can easily exceed infrastructure costs (servers, databases, etc.). Budget $2,000-10,000/month for data subscriptions at a small fund, much more at larger funds with comprehensive data needs. Factor this into your overall technology budget from the start.

## Working with Data Vendors

**APIs change frequently**

Data vendors update their APIs more often than you'd expect. They rename fields, change data formats, add new attributes, deprecate old endpoints. Your integrations break when this happens.

Pay attention to vendor communications. They usually announce breaking changes weeks in advance via email or their changelog. Set up notifications so you see these announcements. Budget time to update your integrations when schemas change.

Use validation (Zod, Pydantic - covered in [Integrations and APIs](/part-3-technical-foundations/integrations-and-apis)) to catch schema changes early. When a vendor changes their API, your validation will fail and alert you immediately, rather than silently corrupting your data.

**Collaborate with newer vendors**

If you're working with a newer data vendor (especially startups building APIs for the VC market), provide feedback on their API design. They want customers to succeed and are often open to suggestions.

If their API returns data in an awkward format, tell them. If they're missing fields you need, ask for them. If rate limits are too restrictive, negotiate. If they only provide CSV but you need Parquet, request it. This is win-win: they improve their product based on real usage, you get an API that's easier to work with.

Established vendors are less flexible, but newer vendors building for the VC market often appreciate detailed feedback and will make changes if multiple customers request them.

**Support and documentation**

Vendor quality varies significantly in support and documentation:
- Some have excellent docs, responsive support, active communities
- Some have minimal docs, slow support, no community
- Some provide developer relations people who help with integration

Factor this into vendor selection. If you're building critical infrastructure on a vendor's data, you need good documentation and reliable support. Don't just evaluate the data quality - evaluate whether you can actually build on top of it.

## The Bottom Line

Data providers are foundational infrastructure. You need external data about companies, funding, people, and markets. You can't build VC technology using only internal data.

Choose vendors based on what data you actually need. Don't subscribe to everything. Test accuracy using your portfolio companies. Understand coverage differences (stage, geography, sector).

Vendors deliver data via APIs (real-time, good for applications) or files (bulk, good for data warehouse loading). Prefer Parquet over CSV for files. Use bulk exports when you need lots of data, use APIs for real-time enrichment.

Data providers are expensive. Budget $2,000-10,000+/month. Understand pricing models (per-request, tiers, flat subscriptions). Monitor spending, cache data, negotiate with vendors.

APIs change frequently. Pay attention to vendor notifications about schema changes. Use validation to catch breaking changes early. Influence newer vendors with feedback - it's win-win.

In the next chapter, we'll cover data modeling for venture capital: how to structure your data, the critical distinction between companies and deals, and how to model the investment lifecycle.
